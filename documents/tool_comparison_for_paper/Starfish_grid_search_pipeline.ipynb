{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5623c3",
   "metadata": {},
   "source": [
    "### Installation\n",
    "\n",
    "In terminal:\n",
    "\n",
    "```\n",
    "conda create -n starfish python=3.7  \n",
    "conda activate starfish  \n",
    "pip install starfish[napari]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f97a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from starfish import data\n",
    "\n",
    "import tifffile as tif\n",
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import skimage.io\n",
    "import tempfile\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import copy\n",
    "from scipy import spatial\n",
    "\n",
    "from slicedimage import ImageFormat\n",
    "from starfish.experiment.builder import format_structured_dataset\n",
    "\n",
    "from starfish import Experiment\n",
    "from starfish.types import Axes\n",
    "\n",
    "# Decode spots with SimpleLookupDecoder\n",
    "from starfish.spots import DecodeSpots\n",
    "from starfish.spots import FindSpots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effc5556",
   "metadata": {},
   "source": [
    "### Set original images dir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/YOUR/PATH/HERE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84342e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_images_dir = os.path.join(path, 'ORG_IMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee28bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ims_paths = glob(os.path.join(org_images_dir,'*','*.tif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657056e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those images are used for accuracy analysis\n",
    "org_simul_ims_paths = [p for p in org_ims_paths \n",
    "                       if \"embryos_FISH\" not in p\n",
    "                      and \"3000spots\" not in p\n",
    "                      and os.path.exists(f'{p[:-4]}.loc')]\n",
    "\n",
    "## Those images are used for execution time analysis:\n",
    "org_embryo_ims_paths = [p for p in org_ims_paths if \"embryos_FISH\" in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4598f261",
   "metadata": {},
   "source": [
    "### Define/create analysis directories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdbf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_dir = os.path.join(path, 'starfish')\n",
    "os.makedirs(sf_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538b1286",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_prep_ims_dir = os.path.join(sf_dir, 'prep_spacext_ims')\n",
    "os.makedirs(sf_prep_ims_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacext_ims_dir = os.path.join(sf_dir, 'spacext_ims')\n",
    "os.makedirs(spacext_ims_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ca3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path_simul = os.path.join(sf_dir, 'results')\n",
    "os.makedirs(results_path_simul, exist_ok=True)\n",
    "\n",
    "results_path_embryos = os.path.join(sf_dir, 'embryos_results')\n",
    "os.makedirs(results_path_embryos, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949950af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison of similar number of points as RSFISH found for each embryo, csv of data from RSFISH\n",
    "# Assuming that more points take longer to analyse\n",
    "\n",
    "df_RSFISH_results_path = 'PATH_TO/RSFISH_embryos_npoints_and_times.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb530f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_embryos_df_path = 'PATH/TO/DESIRED/LOCATION/OF/EMBRYOS/RESULTS.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1765a6",
   "metadata": {},
   "source": [
    "# Convert Image Data to SpaceTx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db740d1",
   "metadata": {},
   "source": [
    "#### Create spaceTX formated for all images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeb23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im_path in org_ims_paths: \n",
    "\n",
    "    im = tif.imread(im_path)\n",
    "    \n",
    "    # columns: r, ch, zplane\n",
    "    fovs = [\n",
    "        [\n",
    "            (0, 0, i) for i in range(im.shape[0])\n",
    "        ],\n",
    "    ]\n",
    "\n",
    "    im_dir = os.path.basename(os.path.dirname(im_path))\n",
    "    \n",
    "    # Time analysis done on the embryo dir:\n",
    "    if im_dir=='embryos_FISH':\n",
    "        zc_max = 358.0\n",
    "    # accuracy analysis done on simulated data\n",
    "    else:\n",
    "        str_xy = im_dir.split('Sigxy ')[1].split(' SigZ')[0]\n",
    "        str_xy = 1.0+float('0.'+str_xy.split('pt')[1]) if 'pt' in str_xy else int(str_xy)\n",
    "        str_z = int(im_dir.split('SigZ ')[1])\n",
    "        \n",
    "        zc_max = 256.0*(str_z/str_xy)\n",
    "    \n",
    "    coordinates_of_fovs = [\n",
    "        {\n",
    "            'xc_min': 0.0,\n",
    "            'xc_max': 256.0,\n",
    "            'yc_min': 0.0,\n",
    "            'yc_max': 256.0,\n",
    "            'zc_min': 0.0,\n",
    "            'zc_max': zc_max,\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # create example image tiles that adhere to the structured data schema\n",
    "    primary_dir = os.path.join(sf_prep_ims_dir, os.path.basename(os.path.dirname(im_path)), os.path.basename(im_path)[:-4], \"primary_dir\")\n",
    "    os.makedirs(primary_dir, exist_ok=True)\n",
    "\n",
    "    for fov_id, fov in enumerate(fovs):\n",
    "        for round_label, ch_label, zplane_label in fov:\n",
    "            primary_path = os.path.join(\n",
    "                primary_dir, f\"primary-f{fov_id}-r{round_label}-c{ch_label}-z{zplane_label}.tiff\")\n",
    "            skimage.io.imsave(primary_path, im[zplane_label])\n",
    "\n",
    "    # write coordinates file for primary:\n",
    "    with open(os.path.join(primary_dir, \"coordinates.csv\"), \"w\") as fh:\n",
    "        csv_writer = csv.DictWriter(\n",
    "            fh,\n",
    "            [\n",
    "                'fov', 'round', 'ch', 'zplane',\n",
    "                'xc_min', 'yc_min', 'zc_min', 'xc_max', 'yc_max', 'zc_max',\n",
    "            ]\n",
    "        )\n",
    "        csv_writer.writeheader()\n",
    "        for fov_id, (fov_info, coordinate_of_fov) in enumerate(zip(fovs, coordinates_of_fovs)):\n",
    "            for round_label, ch_label, zplane_label in fov:\n",
    "                tile_coordinates = coordinate_of_fov.copy()\n",
    "                tile_coordinates.update({\n",
    "                    'fov': fov_id,\n",
    "                    'round': round_label,\n",
    "                    'ch': ch_label,\n",
    "                    'zplane': zplane_label,\n",
    "                })\n",
    "                csv_writer.writerow(tile_coordinates)\n",
    "                \n",
    "                \n",
    "                \n",
    "    primary_out = os.path.join(spacext_ims_dir, os.path.basename(os.path.dirname(im_path)), os.path.basename(im_path)[:-4], \"primary\")\n",
    "    os.makedirs(primary_out, exist_ok=True)\n",
    "\n",
    "    format_structured_dataset(\n",
    "        primary_dir,\n",
    "        os.path.join(primary_dir, \"coordinates.csv\"),\n",
    "        primary_out,\n",
    "        ImageFormat.TIFF,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5226ff27",
   "metadata": {},
   "source": [
    "# Finding Spots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8091df92",
   "metadata": {},
   "source": [
    "### Define spot finding function\n",
    "We use blob_detector, but stardist has many options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d040884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spots(imgs, min_sigma, max_sigma, num_sigma, threshold):\n",
    "\n",
    "    p = FindSpots.BlobDetector(\n",
    "        min_sigma=min_sigma,\n",
    "        max_sigma=max_sigma,\n",
    "        num_sigma=num_sigma,\n",
    "        threshold=threshold,\n",
    "        measurement_type='mean', \n",
    "        exclude_border=False\n",
    "    )\n",
    "    \n",
    "    intensities = p.run(image_stack=imgs, n_processes=40)\n",
    "    return intensities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607e0ea2",
   "metadata": {},
   "source": [
    "# Simulated Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf6069",
   "metadata": {},
   "source": [
    "## Quick grid search\n",
    "on the parameters (sigma and threshold) to try to optimize blob detection on the simulated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb1b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load image:\n",
    "\n",
    "## Some of those more specific values were chosen after the first run.\n",
    "sigs = [2,4,5]\n",
    "thrs = [0.001, 0.002, 0.0001, 0.000145, 0.0000404, 0.0000412, 0.000042, 0.0000428, 0.000043, 0.0000439, 0.000044, 0.000045, 0.000046, \n",
    "        0.000047, 0.000048, 0.0000483, 0.000049, 0.00005, 0.000065125, 0.000074, 0.000075, 0.000076, 0.000077, \n",
    "        0.000078, 0.000079, 0.00008, 0.0000805, 0.00009, 0.000095]\n",
    "\n",
    "for i,im_path in enumerate(org_simul_ims_paths):\n",
    "\n",
    "    im_dir = os.path.basename(os.path.dirname(im_path))\n",
    "    im_name = os.path.basename(im_path[:-4])\n",
    "    \n",
    "    # load image:\n",
    "    experiment = Experiment.from_json(os.path.join(\n",
    "    spacext_ims_dir, im_dir, im_name, 'primary', 'experiment.json'))\n",
    "\n",
    "    imgs = experiment.fov().get_image('primary')\n",
    "\n",
    "    # Find spots:\n",
    "\n",
    "    for sig in sigs:\n",
    "\n",
    "\n",
    "        for thr in thrs:\n",
    "\n",
    "            print(im_path, i, sig, thr)\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            spotss = find_spots(imgs, 0, sig, sig, thr)\n",
    "\n",
    "            gt_n_spots = int(im_name.split('Poiss_')[1].split('spots')[0])\n",
    "\n",
    "            if abs( n_spots - spotss.count_total_spots() ) == 0:\n",
    "                flag =True\n",
    "\n",
    "            diff_nspots = abs(gt_n_spots - spotss.count_total_spots())\n",
    "            \n",
    "            print(f'gt_nspots - nspots = {diff_nspots}')\n",
    "\n",
    "            if diff_nspots < 5:\n",
    "\n",
    "                # Decode:\n",
    "                decoder = DecodeSpots.SimpleLookupDecoder(codebook=experiment.codebook)\n",
    "                decoded_intensities = decoder.run(spots=spotss)\n",
    "\n",
    "                exe_time = time.time() - start\n",
    "                exe_time = f'{exe_time:.3g}'\n",
    "\n",
    "                filename = f'{im_dir}__{im_name}__sig{sig}_thr{thr}__exetime{exe_time}.csv'\n",
    "\n",
    "                decoded_intensities.to_dataframe(\"results\")[[\"x\",\"y\",\"z\"]].reset_index(drop=True).to_csv(\n",
    "                os.path.join(results_path_simul,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211bb4f4",
   "metadata": {},
   "source": [
    "### Analyse spot detection accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831538aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leo's code:\n",
    "\n",
    "# This function compares two arrays:\n",
    "# Unmod = ground truth array\n",
    "# More_than = detections from one of the programs\n",
    "\n",
    "#Function checks if points in More_than are close/match points in GT array (under certain distance)\n",
    "\n",
    "#Returns: \n",
    "# # of undetected ground truth points\n",
    "# # spurious detections\n",
    "# and average distance between detection and associated points\n",
    "\n",
    "def profile_detections(unmod, more_than):\n",
    "\n",
    "    min_dist = 2\n",
    "\n",
    "    distance_arr = []\n",
    "\n",
    "    removedItems = True\n",
    "    euc_dist = 0\n",
    "\n",
    "    while (removedItems and len(more_than) != 0 and len(unmod) != 0 ):\n",
    "        #print(\"loop\")\n",
    "\n",
    "        minDist = 10000\n",
    "        minIndexUnmod = -1\n",
    "        minIndexMore_Than = -1\n",
    "        counter = 0\n",
    "        kd_copy = copy.deepcopy(more_than)\n",
    "        kdtree = spatial.KDTree(kd_copy)\n",
    "\n",
    "        for item in unmod:\n",
    "            distance,index = kdtree.query(item) # a new KD tree is made\n",
    "            if ( distance < minDist ):\n",
    "                minDist = distance\n",
    "                minIndexUnmod = counter\n",
    "                minIndexMore_Than = index\n",
    "                #print(minDist, counter, item)\n",
    "            counter = counter + 1\n",
    "\n",
    "        if ( minDist < min_dist): # if less than min dist\n",
    "            more_than = np.delete(more_than, minIndexMore_Than, axis = 0 ) # delete mod ind\n",
    "            unmod = np.delete(unmod,minIndexUnmod, axis = 0) #delete unmod ind\n",
    "            #print(len(more_than),distance) # sanity checkd\n",
    "            removedItems = True\n",
    "            distance_arr.append(minDist) # if we want to extrat stat ig\n",
    "\n",
    "        else:\n",
    "            removedItems = False\n",
    "    if (len(distance_arr) >0):\n",
    "        euc_dist = np.mean(np.asarray(distance_arr))\n",
    "        \n",
    "    return(len(unmod), len(more_than), euc_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d455716",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = glob(os.path.join(results_path_simul,'*.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e856096",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_results_list = []\n",
    "best_results_files = []\n",
    "    \n",
    "for i,im_path in enumerate(org_simul_ims_paths):\n",
    "    \n",
    "    gt_dir = os.path.basename(os.path.dirname(im_path))\n",
    "    gt_filename = os.path.basename(im_path[:-4])\n",
    "\n",
    "    gt_path = f'{im_path[:-4]}.loc')\n",
    "\n",
    "    df = pd.read_csv(gt_path, sep = \"\\s+\", header=None)\n",
    "    gt_spots = df.to_numpy()[:,:-1] - np.array([0.5,0.5,1])\n",
    "\n",
    "    im_results = [r for r in all_results if gt_dir in r and gt_filename in r]\n",
    "\n",
    "    im_final_diff_all = []\n",
    "\n",
    "    for result_path in im_results:\n",
    "\n",
    "        detected_spots = pd.read_csv(result_path, index_col=0)[[\"y\",\"x\",\"z\"]].to_numpy()\n",
    "\n",
    "        diff_results = list(profile_detections(gt_spots, detected_spots))\n",
    "\n",
    "        n_spots = int(gt_path.split(\"spots\")[0].split(\"_\")[-1])\n",
    "        \n",
    "        ## make diff_results in the format of - \"n_spots, FN, FP, distance\"\n",
    "        diff_results.insert(0, n_spots)\n",
    "        diff_results = \",\".join([str(d_r) for d_r in diff_results])\n",
    "\n",
    "        im_final_diff_all.append(diff_results)\n",
    "\n",
    "    ## Score of each result file is FN+FP (with best score is the lowest score\n",
    "    scores = [int(r.split(',')[1]) + int(r.split(',')[2]) for r in im_final_diff_all]\n",
    "    l_min = min(scores)\n",
    "    idx = scores.index(l_min)\n",
    "    best_diff = im_final_diff_all[idx]\n",
    "    best_result_file = im_results[idx]\n",
    "\n",
    "    diff_results_list.append(best_diff)\n",
    "    best_results_files.append(best_result_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e603743",
   "metadata": {},
   "source": [
    "#### Save best result files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca8376d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(sf_dir, 'results_nspots_missed_overdetected_distance.txt'),'w') as f:\n",
    "    f.write(\"\\n\".join(diff_results_list))\n",
    "    \n",
    "with open(os.path.join(sf_dir,'best_result_files.txt'),'w') as f:\n",
    "    f.write(\"\\n\".join(best_results_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda2462",
   "metadata": {},
   "source": [
    "## Embryos\n",
    "Those images were analysed for execution time analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca615c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison of similar number of points as RSFISH found for each embryo, load the data from RSFISH\n",
    "# Assuming that more points take longer to analyse\n",
    "\n",
    "df_rs = pd.read_csv('PATH_TO/RSFISH_embryos_npoints_and_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad94bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df_rs.name.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6ca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## check that all embryos exist in org dir:\n",
    "embryos_names = [os.path.basename(p) for p in org_embryo_ims_paths]\n",
    "\n",
    "## Should output nothing!\n",
    "set(names) - set(embryos_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0100d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take only embryos that were analysed for the rest of the tools\n",
    "embryos_paths = [os.path.join(os.path.dirname(embryos_paths[0]), n) for n in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab47034",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs = [2]\n",
    "thrs = [0.009, 0.0105, 0.011, 0.0125, 0.012, 0.013, 0.014, 0.016, 0.016, 0.02, 0.25]\n",
    "\n",
    "for i,im_path in enumerate(embryos_paths):\n",
    "\n",
    "    im_dir = os.path.basename(os.path.dirname(im_path))\n",
    "    im_name = os.path.basename(im_path[:-4])\n",
    "    \n",
    "    # load image:\n",
    "    experiment = Experiment.from_json(os.path.join(\n",
    "    spacext_ims_dir, im_dir, im_name, 'primary', 'experiment.json'))\n",
    "\n",
    "    imgs = experiment.fov().get_image('primary')\n",
    "\n",
    "    # Find spots:\n",
    "\n",
    "    for sig in sigs:\n",
    "\n",
    "        for thr in thrs:\n",
    "\n",
    "            start = time.time()\n",
    "            \n",
    "            spotss = find_spots(imgs, 0, sig, sig, thr)\n",
    "\n",
    "            decoder = DecodeSpots.SimpleLookupDecoder(codebook=experiment.codebook)\n",
    "            decoded_intensities = decoder.run(spots=spotss)\n",
    "\n",
    "            exe_time = time.time() - start\n",
    "            exe_time = f'{exe_time:.3g}'\n",
    "            \n",
    "            nspots = spotss.count_total_spots()\n",
    "            gt_nspots = int(df_rs.at[i,\"n_spots\"])\n",
    "            print(f'found {nspots}, GT {gt_nspots}')\n",
    "\n",
    "            filename = f'{im_dir}__{im_name}__sig{sig}_thr{thr}__exetime{exe_time}_nspots{nspots}_RSnspots{gt_nspots}.csv'\n",
    "\n",
    "            decoded_intensities.to_dataframe(\"results\")[[\"x\",\"y\",\"z\"]].reset_index(drop=True).to_csv(\n",
    "            os.path.join(results_path_embryos,filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c26f7",
   "metadata": {},
   "source": [
    "#### Compare number of spots to rs_fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e463245",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = glob(os.path.join(results_path_embryos,\"*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97c2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get all result files for each embryo\n",
    "\n",
    "embryos_results = []\n",
    "\n",
    "for n in names:\n",
    "    \n",
    "    embryo_result = [r for r in all_results if n[:-4] in r]\n",
    "    \n",
    "    embryos_results.append(embryo_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4670352",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_files = []\n",
    "\n",
    "for i in df_rs.index:\n",
    "    nspots_rs = df_rs.at[i,\"n_spots\"]\n",
    "    \n",
    "    mini = 10000\n",
    "    for r in embryos_results[i]:\n",
    "        \n",
    "        nspots = pd.read_csv(r).shape[0]\n",
    "        diff = abs(nspots_rs-nspots)\n",
    "        \n",
    "        if diff<mini:\n",
    "            best_file = r\n",
    "            mini = diff\n",
    "            \n",
    "    best_files.append(best_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81871538",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = [float(r.split('exetime')[1].split(\"_\")[0]) for r in best_files]\n",
    "names = [r.split(\"embryos_FISH__\")[1].split(\"__\")[0] for r in best_files]\n",
    "n_spots = [pd.read_csv(r).shape[0] for r in best_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79602409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"time\": times, \n",
    "                      \"name\": names,\n",
    "                      \"n_spots\": n_spots,\n",
    "                      \"method\": \"starFISH\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5449b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(results_embryos_df_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a4886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
