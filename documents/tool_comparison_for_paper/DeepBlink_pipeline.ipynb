{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3d6e45",
   "metadata": {},
   "source": [
    "DeepBlink is a 2D CNN to detect spots:  \n",
    "\n",
    "### Installation \n",
    "```\n",
    "conda create -n starfish python=3.7  \n",
    "conda activate starfish  \n",
    "```\n",
    "(if GPUs are available install cuda and tf2_gpu according to the nvidia drive)  \n",
    "```\n",
    "conda install -c bbquercus deepblink  \n",
    "```\n",
    "\n",
    "the network only works on 2d images\n",
    "but they support 3d by offering a non maximal suppression:  \n",
    "https://github.com/BBQuercus/deepBlink/blob/master/examples/3d_prediction.ipynb  \n",
    "(used below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96100a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca742b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb1ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_gpu = len(tf.config.experimental.list_physical_devices('GPU')) > 0\n",
    "is_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8455849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import pandas as pd\n",
    "import tifffile as tif\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa806b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepblink as pink\n",
    "from skimage import io\n",
    "import trackpy as tp\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40942bc6",
   "metadata": {},
   "source": [
    "#### Load pretrained model\n",
    "We trained our own network, but results were not as good on the simulated data.  \n",
    "and tested the pretrained netwrok \"smfish.n5, but its not as good.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9945db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pink.io.load_model(\"particle.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772b577",
   "metadata": {},
   "source": [
    "## Simulated Data\n",
    "To analyze accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03cb4b7",
   "metadata": {},
   "source": [
    "#### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb3e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_ims_dir = 'PATH/TO/IMAGES'\n",
    "result_dir_simul = 'results_simul'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8ba867",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71920d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tifs = [f for f in glob(os.path.join(ss_dir, '*', '*spots*.tif')) if \"3000spots\" not in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef82c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_csvs = [f'{f[:-4]}.loc' for f in all_tifs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf37f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## if an image is missing a loc file\n",
    "to_del = []\n",
    "for i,f in enumerate(all_csvs):\n",
    "    if not os.path.exists(f):\n",
    "        to_del.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(to_del):\n",
    "    del all_csvs[i]\n",
    "    del all_tifs[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cef6e",
   "metadata": {},
   "source": [
    "save a list of corresponding filename and file number in the list.\n",
    "will be used for all analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1076a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get imidiate dir and file name:\n",
    "all_tifs = [\"/\".join(f.split('/')[-2:]) for f in all_tifs]\n",
    "df_name_nums = pd.DataFrame({'name':all_tifs}) #'num': range(len(all_tifs)) ,\n",
    "df_name_nums.to_csv('ims_and_corresponding_num.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba23a03",
   "metadata": {},
   "source": [
    "#### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a44b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(result_dir_simul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_refinement = 3\n",
    "pad_width = radius_refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee10f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "dfs = []\n",
    "\n",
    "for i,f in enumerate(all_tifs):\n",
    "    im_3d = tif.imread(os.path.join(org_ims_dir, f))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    time_im = 0\n",
    "\n",
    "    for slice, image_curr in enumerate(im_3d):\n",
    "        \n",
    "        beg_time = time.time()\n",
    "        \n",
    "        # deepBlink prediction\n",
    "        yx = pink.inference.predict(image=image_curr, model=model)\n",
    "        y, x = yx.T.copy()\n",
    "        \n",
    "        time_im += (time.time() - beg_time)\n",
    "\n",
    "        # pad to avoid error for spot close to the edges\n",
    "        yx = yx + pad_width\n",
    "        image_curr = np.pad(\n",
    "            image_curr, pad_width=pad_width, mode='constant', constant_values = 0\n",
    "        )\n",
    "\n",
    "        # Refinement with trackpy\n",
    "        df_curr = tp.refine_com(\n",
    "            raw_image=image_curr, image=image_curr, radius=radius_refinement, coords=yx\n",
    "        )\n",
    "        df_curr[\"x\"] = x\n",
    "        df_curr[\"y\"] = y\n",
    "        df_curr[\"slice\"] = slice\n",
    "        df = df.append(df_curr, ignore_index=True)\n",
    "        \n",
    "    times.append(time_im)\n",
    "        \n",
    "    df.to_csv(os.path.join(result_dir_simul ,f'{i}.csv'), index=False)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5756b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(times).to_csv(os.path.join(result_dir_simul ,f'times.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1ff5a4",
   "metadata": {},
   "source": [
    "#### Unite spots (2D to 3D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_range = 2\n",
    "gap_frames = 0\n",
    "min_frames = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cef75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_clean = []\n",
    "times1 = []\n",
    "\n",
    "for df in dfs:\n",
    "    if not df.empty:\n",
    "\n",
    "        beg_time = time.time()\n",
    "        \n",
    "        track = tp.link(df.rename({\"slice\": \"frame\"}, axis=1), \n",
    "                         search_range=search_range, memory=gap_frames)\n",
    "        track = tp.filter_stubs(track, threshold=min_frames\n",
    "                                ).rename({\"frame\": \"slice\"}, axis=1)\n",
    "\n",
    "        # Index of brightest particles\n",
    "        idx = track.groupby([\"particle\"])[\"mass\"].transform(max) ==track[\"mass\"]\n",
    "        df_nms = track[idx]\n",
    "\n",
    "        # Remove tracks from all spots\n",
    "        df_without_track = df[\n",
    "            ~df.set_index([\"x\", \"y\", \"slice\", \"mass\"]).index.isin(\n",
    "                track.set_index([\"x\", \"y\", \"slice\", \"mass\"]).index\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Add back nms (brightest spots)\n",
    "        df_clean = pd.concat([df_nms, df_without_track]).reset_index(drop=True)\n",
    "\n",
    "        times1.append(time.time()-beg_time)\n",
    "        \n",
    "        dfs_clean.append(df_clean)\n",
    "        #print(df_clean.shape)\n",
    "    else:\n",
    "        dfs_clean.append(0)\n",
    "        times1.append(np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c5052",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(times1).to_csv(os.path.join(result_dir_simul ,f'times1.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fec8348",
   "metadata": {},
   "source": [
    "#### Compare to GT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leo's code:\n",
    "\n",
    "# This function compares two arrays:\n",
    "# Unmod = ground truth array\n",
    "# More_than = detections from one of the programs\n",
    "\n",
    "#Function checks if points in More_than are close/match points in GT array (under certain distance)\n",
    "\n",
    "#Returns: \n",
    "# # of undetected ground truth points\n",
    "# # spurious detections\n",
    "# and average distance between detection and associated points\n",
    "\n",
    "def profile_detections(unmod, more_than):\n",
    "\n",
    "    min_dist = 2\n",
    "\n",
    "    distance_arr = []\n",
    "\n",
    "    removedItems = True\n",
    "    euc_dist = 0\n",
    "\n",
    "    while (removedItems and len(more_than) != 0 and len(unmod) != 0 ):\n",
    "        #print(\"loop\")\n",
    "\n",
    "        minDist = 10000\n",
    "        minIndexUnmod = -1\n",
    "        minIndexMore_Than = -1\n",
    "        counter = 0\n",
    "        kd_copy = copy.deepcopy(more_than)\n",
    "        kdtree = spatial.KDTree(kd_copy)\n",
    "\n",
    "        for item in unmod:\n",
    "            distance,index = kdtree.query(item) # a new KD tree is made\n",
    "            if ( distance < minDist ):\n",
    "                minDist = distance\n",
    "                minIndexUnmod = counter\n",
    "                minIndexMore_Than = index\n",
    "                #print(minDist, counter, item)\n",
    "            counter = counter + 1\n",
    "\n",
    "        if ( minDist < min_dist): # if less than min dist\n",
    "            more_than = np.delete(more_than, minIndexMore_Than, axis = 0 ) # delete mod ind\n",
    "            unmod = np.delete(unmod,minIndexUnmod, axis = 0) #delete unmod ind\n",
    "            #print(len(more_than),distance) # sanity checkd\n",
    "            removedItems = True\n",
    "            distance_arr.append(minDist) # if we want to extrat stat ig\n",
    "\n",
    "        else:\n",
    "            removedItems = False\n",
    "    if (len(distance_arr) >0):\n",
    "        euc_dist = np.mean(np.asarray(distance_arr))\n",
    "        \n",
    "    return(len(unmod), len(more_than), euc_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_results_list = []\n",
    "\n",
    "for idx in df_name_nums.index:\n",
    "\n",
    "    ## GT ##\n",
    "    gt_path = df_name_nums.at[idx,'name']\n",
    "    gt_dir = os.path.join('..', 'Selected_simulation')\n",
    "\n",
    "    gt_path = os.path.join(gt_dir, gt_path[:-4] + '.loc')\n",
    "        \n",
    "    df = pd.read_csv(gt_path, sep = \"\\s+\", header=None)\n",
    "    gt_spots = df.to_numpy()[:,:-1] - np.array([0.5,0.5,1])\n",
    "\n",
    "    df_db = dfs_clean[idx]\n",
    "    \n",
    "    if isinstance(df_db,int):\n",
    "        continue\n",
    "        \n",
    "    detected_spots = df_db[df_db.particle.notna()][[\"y\",\"x\",\"slice\"]].to_numpy()    \n",
    "\n",
    "    diff_results = list(profile_detections(gt_spots, detected_spots))\n",
    "    \n",
    "    n_spots = int(gt_path.split(\"spots\")[0].split(\"_\")[-1])\n",
    "    \n",
    "    diff_results.insert(0, n_spots)\n",
    "    diff_results = \",\".join([str(d_r) for d_r in diff_results])\n",
    "    \n",
    "    diff_results_list.append(diff_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdb733",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(result_dir_simul, 'results_nspots_missed_overdetected_distance.txt'),'w') as f:\n",
    "    f.write(\"\\n\".join(diff_results_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
