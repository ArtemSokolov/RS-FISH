{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56da7774",
   "metadata": {},
   "source": [
    "For the previous step - Big-FISH version: 0.5.0  \n",
    "\n",
    "This notebook is used to compare all bigfish results to GT.  \n",
    "However, because so many results were produced by a grid search, this was actually not ran as a notebook,  \n",
    "but was ran on the cluster with a job for each original file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c08c0d",
   "metadata": {},
   "source": [
    "#####  sh file that called this python script (mdc cluster, sun-grid):\n",
    "\n",
    "```\n",
    "#!/bin/sh\n",
    "# Job script with qsub-options\n",
    "##$ -pe smp 2\n",
    "##$ -pe orte 4\n",
    "#$ -V -N \"BF_analysis\"\n",
    "#$ -l h_rt=80:00:00 -l h_vmem=10G -l h_stack=128M -l data -cwd\n",
    "\n",
    "##$ -o bf-log.txt\n",
    "##$ -e bf-log.txt\n",
    "\n",
    "# export NSLOTS=8\n",
    "# neccessary to prevent python error\n",
    "export OPENBLAS_NUM_THREADS=4\n",
    "# export NUM_THREADS=8\n",
    "python bigfish_comparison.py --im_num $IM_NUM  &> log${IM_NUM}.txt\n",
    "```  \n",
    "\n",
    "##### pythos script that called the shell script:\n",
    "\n",
    "```\n",
    "import os\n",
    "\n",
    "# Thr loop\n",
    "for i in range(50):\n",
    "\n",
    "\tcommand = f'qsub -v IM_NUM={i} bigfish_analyse_results.sh'\n",
    "\tos.system(command)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3498f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    "import copy\n",
    "from scipy import spatial\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'PATHTO/Selected_simulation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b52e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### im_num is a passed argument\n",
    "## for each original image, all grid search results will be compared to GT here\n",
    "\n",
    "parser = argparse.ArgumentParser(description='for cluster multiple jobs - im_num is given as arg')\n",
    "parser.add_argument(\"--im_num\")\n",
    "args = parser.parse_args()\n",
    "if args.im_num:\n",
    "    im_num = int(args.im_num)\n",
    "else:\n",
    "    print('need to pass image number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7ba9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Leo's code:\n",
    "\n",
    "def profile_detections(unmod, more_than): \n",
    "\n",
    "    min_dist = 2 \n",
    "\n",
    "    distance_arr = [] \n",
    "\n",
    "    removedItems = True \n",
    "    euc_dist = 0 \n",
    "\n",
    "    while (removedItems and len(more_than) != 0 and len(unmod) != 0 ): \n",
    "        #print(\"loop\") \n",
    "\n",
    "        minDist = 10000 \n",
    "        minIndexUnmod = -1 \n",
    "        minIndexMore_Than = -1 \n",
    "        counter = 0 \n",
    "        kd_copy = copy.deepcopy(more_than) \n",
    "        kdtree = spatial.KDTree(kd_copy) \n",
    "\n",
    "        for item in unmod: \n",
    "            distance,index = kdtree.query(item) # a new KD tree is made \n",
    "            if ( distance < minDist ): \n",
    "                minDist = distance \n",
    "                minIndexUnmod = counter \n",
    "                minIndexMore_Than = index \n",
    "                #print(minDist, counter, item) \n",
    "            counter = counter + 1 \n",
    "\n",
    "        if ( minDist < min_dist): # if less than min dist \n",
    "            more_than = np.delete(more_than, minIndexMore_Than, axis = 0 ) # delete mod ind \n",
    "            unmod = np.delete(unmod,minIndexUnmod, axis = 0) #delete unmod ind \n",
    "            #print(len(more_than),distance) # sanity checkd \n",
    "            removedItems = True \n",
    "            distance_arr.append(minDist) # if we want to extrat stat ig \n",
    "\n",
    "        else: \n",
    "            removedItems = False \n",
    "    if (len(distance_arr) >0): \n",
    "        euc_dist = np.mean(np.asarray(distance_arr)) \n",
    "\n",
    "    return(len(unmod), len(more_than), euc_dist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca85151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_paths = glob(os.path.join(path, '*','FishQuant_result*.csv')) \n",
    "\n",
    "all_paths = [p for p in all_paths if (\"embryo\" not in p) and (\"3000spo\" not in p) and\n",
    " (('Empty Bg Density Range Sigxy 2 SigZ 2' not in p) or ('Poiss_300spots_bg_200_2_I_300_0_img2.tif' not in p))] \n",
    "\n",
    "loc_files = glob(os.path.join(path, '*','*.loc'))\n",
    "loc_files = [l for l in loc_files if \"3000spo\" not in l] \n",
    "loc_file = loc_files[im_num]\n",
    "\n",
    "all_paths = [f for f in all_paths if loc_file.split('/')[-2] in f and loc_file.split('/')[-1][:-4] in f]\n",
    "\n",
    "df = pd.read_csv(loc_file, sep = \"\\s+\", header=None) \n",
    "gt_spots = df.to_numpy()[:,:-1] - np.array([0.5,0.5,1])\n",
    "\n",
    "loc_diffs = []\n",
    "loc_all_files = []\n",
    "\n",
    "for i,p in enumerate(all_paths): \n",
    "\n",
    "    num_lines = sum(1 for line in open(p))\n",
    "\n",
    "    if (\"_30spots\" in p and num_lines<60) or (\"_300spots\" in p and num_lines<500):\n",
    "    \n",
    "        detected_spots = pd.read_csv(os.path.join(path,p))[[\"y\",\"x\",\"z\"]].to_numpy()\n",
    "    \n",
    "        diff_results = list(profile_detections(gt_spots, detected_spots))\n",
    "        loc_diffs.append([str(d) for d in diff_results])\n",
    "        loc_all_files.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56eeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'bigfish_diff_results_{im_num}.txt', 'w') as f:\n",
    "    for i,d in enumerate(loc_diffs):\n",
    "        f.write(loc_all_files[i])    \n",
    "        f.write(', ')\n",
    "        f.write(\",\".join(d))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e9ea86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
